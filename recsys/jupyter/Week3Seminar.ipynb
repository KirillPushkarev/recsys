{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as spf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"dnikanorova\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Основная идея: \n",
    "Рекомендовать пользователю треки, которые понравились похожим на него пользователям\n",
    "\n",
    "$$\\hat r_{ui} = h^{-1} \\left( \\frac{\\sum_{v \\in N_i(u)} w_{uv} h(r_{vi})}{\\sum_{v \\in N_i(u)} w_{uv}} \\right)$$\n",
    "\n",
    "$N_i(u)$ - соседи пользователя $u$, которые оценили айтем $i$, \n",
    "$w_{uv}, w_{ij}$ - веса соседей, \n",
    "$h$ - функция нормализации\n",
    "\n",
    "\n",
    "\n",
    "**Нормализация**: В качестве функции нормализации используем среднее время прослушивания\n",
    "\n",
    "**Веса**: Похожих пользователей будем искать по *cosine similarity*\n",
    "\n",
    "**Отсутствующие данные** заполним средним времнем прослушивания по пользователю\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.json(\"/user/dnikanorova/data/top_pop_50k/\")\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (data\n",
    "          .withColumn(\"rating\", spf.when(spf.col(\"time\") > 0.5, 1.0).otherwise(0.0))\n",
    "          .filter(spf.col(\"experiments.TOP_POP\").isin(\"T3\"))\n",
    "          .select(spf.col(\"user\"), spf.col(\"time\"), spf.col(\"recommendation\").cast(\"int\").alias(\"track\"))\n",
    "          .filter(spf.col(\"track\").isNotNull())\n",
    "          .dropDuplicates([\"user\", \"track\"])\n",
    "          .toPandas()\n",
    "     )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных\n",
    "На этом этапе соберем несколько вспомогательных датасетов:\n",
    "\n",
    "1) ***norm*** - датасет с нормализованными данными\n",
    "\n",
    "2) ***interactions_raw*** - матрица взаимодействий user-item \n",
    "\n",
    "3) ***interactions*** - матрица взаимодействий user-item с заполненными значениями\n",
    "\n",
    "4) ***user_similarity_cosine*** - матрица похожести пользователей\n",
    "\n",
    "5) ***sim_user_30_u*** - топ-30 ближаших соседей для пользователя\n",
    "\n",
    "6) ***tracks_by_user*** - треки, прослушанные пользователями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust time by substracting mean value\n",
    "def normalize(df, group_col, value_col): \n",
    "    df['avg'] = df.groupby(group_col)[value_col].transform('mean')\n",
    "    df['time_adj'] = df[value_col] - df['avg']\n",
    "    return df\n",
    "\n",
    "\n",
    "# Create user-item interaction matrix and replace NaN by user or item average\n",
    "def create_interactions(\n",
    "    df, \n",
    "    value_col='time_adj',\n",
    "    user_col=\"user\" ,\n",
    "    item_col=\"track\"\n",
    "):\n",
    "\n",
    "    interactions = pd.pivot_table(df, values=value_col, index=user_col, columns=item_col)\n",
    "    \n",
    "    print(\"Interaction matrix consists of {} users and {} items\".format(interactions.shape[0], interactions.shape[1]))\n",
    "    return interactions\n",
    "  \n",
    "\n",
    "def fill_na(interactions, user_based=False):\n",
    "    return interactions.fillna(0)\n",
    "\n",
    "\n",
    "# Calculate cosine similarity\n",
    "def calculate_cosine_similarity(interactions, user_based=False):\n",
    "    if user_based:\n",
    "        interactions_t = interactions.copy()\n",
    "    else:\n",
    "        interactions_t = interactions.T\n",
    "        \n",
    "    similarity_matrix = cosine_similarity(interactions_t)\n",
    "    np.fill_diagonal(similarity_matrix, 0 )\n",
    "    similarity_df = pd.DataFrame(similarity_matrix,index=interactions_t.index)\n",
    "    similarity_df.columns=interactions_t.index\n",
    "    return similarity_df\n",
    "\n",
    "# find most similar users\n",
    "def find_n_neighbours(df,n):\n",
    "    order = np.argsort(df.values, axis=1)[:, :n]\n",
    "    df = df.apply(lambda x: pd.Series(x.sort_values(ascending=False)\n",
    "           .iloc[:n].index, \n",
    "          index=['top{}'.format(i) for i in range(1, n + 1)]), axis=1)\n",
    "    return df\n",
    "\n",
    "# check interests\n",
    "def get_user_similar_movies( user1, user2 ):\n",
    "    common_tracks = df[df.user == user1].merge(\n",
    "    df[df.user == user2],\n",
    "    on = \"track\",\n",
    "    how = \"inner\" )\n",
    "    return common_tracks\n",
    "\n",
    "# collect tracks listened by users\n",
    "def collect_tracks_by_user(df):\n",
    "    df = df.astype({\"track\": str})\n",
    "    tracks_by_user = df.groupby(by = 'user')['track'].apply(lambda x:','.join(x))\n",
    "    return tracks_by_user\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = normalize(df, value_col=\"time\", group_col=\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_raw = create_interactions(norm)\n",
    "interactions = fill_na(interactions_raw, user_based = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "user_similarity_cosine = calculate_cosine_similarity(interactions, user_based=True)\n",
    "sim_user_30_u = find_n_neighbours(user_similarity_cosine,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks_by_user = collect_tracks_by_user(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение рекомендаций\n",
    "На этом этапе рассчитаем скоры айтемов по формуле \n",
    "\n",
    "$$\\hat r_{ui} = h^{-1} \\left( \\frac{\\sum_{v \\in N_i(u)} w_{uv} h(r_{vi})}{\\sum_{v \\in N_i(u)} w_{uv}} \\right)$$\n",
    "\n",
    "$N_i(u)$ - соседи пользователя $u$, которые оценили айтем $i$, \n",
    "$w_{uv}, w_{ij}$ - веса соседей, \n",
    "$h$ - функция нормализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score tracks\n",
    "def score_tracks(\n",
    "    user,\n",
    "    tracks_by_user, \n",
    "    interactions_raw,\n",
    "    interactions,\n",
    "    similar_users_by_user,\n",
    "    norm\n",
    "):\n",
    "    # get tracks already listened by user\n",
    "    tracks_listen_by_user = interactions_raw.loc[user, :].dropna().index.tolist()\n",
    "    \n",
    "    # get similar users\n",
    "    similar_users = similar_users_by_user.loc[user, :].values.tolist()\n",
    "    \n",
    "    # get tracks from similar users\n",
    "    tracks_of_similar_users = tracks_by_user[tracks_by_user.index.isin(similar_users)]\n",
    "    all_tracks_of_similar_users = list(map(int, ','.join(tracks_of_similar_users.values).split(',')))\n",
    "    \n",
    "    # only take tracks that were not listened by a user\n",
    "    tracks_under_consideration = list(set(all_tracks_of_similar_users) - set(tracks_listen_by_user))\n",
    "    \n",
    "    scores=[]\n",
    "    for item in tracks_under_consideration:\n",
    "        score = score_track(item, interactions_raw, similar_users, norm)\n",
    "        scores.append(score)\n",
    "        \n",
    "    top = np.array(tracks_under_consideration)[np.argsort(scores)[-100:]]\n",
    "\n",
    "    return top\n",
    "\n",
    "\n",
    "def score_track(item, interactions_raw, similar_users, norm):\n",
    "    \n",
    "    item_ratings_by_similars = interactions_raw.loc[similar_users, item].dropna()\n",
    "    similars_rated_item = item_ratings_by_similars.index.values.tolist()\n",
    "    avg_user = norm.query('user == @user')['avg'].values[0]\n",
    "    weights = user_similarity_cosine.loc[user, similars_rated_item]\n",
    "    \n",
    "    numerator = sum(item_ratings_by_similars * weights)\n",
    "    denominator = weights.sum()\n",
    "    score = avg_user + (numerator / denominator)\n",
    "    \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df['user'].unique()\n",
    "\n",
    "tracks_by_user = collect_tracks_by_user(df)\n",
    "\n",
    "with open(DATA_DIR + \"recommendations_5k.json\", \"w\") as rf:\n",
    "    for user in tqdm.tqdm(users):\n",
    "        top = score_tracks(user, tracks_by_user, interactions_raw, interactions, sim_user_30_u, norm)\n",
    "        recommendation = {\n",
    "                \"user\": int(user),\n",
    "                \"tracks\": top.tolist()\n",
    "        }\n",
    "        rf.write(json.dumps(recommendation) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
